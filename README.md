<h1 align="center">
  <br>
  agentic-terminal-workbench
  <br>
</h1>

<h4 align="center">A lightweight CLI for chatting with OpenAI models - with optional <a href="https://composio.dev" target="_blank">Composio</a> toolkits</h4>

<p align="center">
  <a href="https://github.com/shricodev/agentic-terminal-workbench/blob/main/LICENSE">
    <img src="https://img.shields.io/github/license/shricodev/agentic-terminal-workbench?style=flat-square" alt="license">
  </a>
  <img src="https://img.shields.io/badge/node-%3E%3D18-brightgreen?style=flat-square&logo=node.js&logoColor=white" alt="node version">
  <img src="https://img.shields.io/badge/TypeScript-5.9-blue?style=flat-square&logo=typescript&logoColor=white" alt="typescript">
  <a href="https://github.com/shricodev/agentic-terminal-workbench/pulls">
    <img src="https://img.shields.io/badge/PRs-welcome-brightgreen?style=flat-square" alt="PRs welcome">
  </a>
</p>

## Table of Contents

- [Key Features](#key-features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Configuration](#configuration)
- [CLI Reference](#cli-reference)
- [How Composio Mode Works](#how-composio-mode-works)
- [Project Structure](#project-structure)
- [Development](#development)
- [Credits](#credits)
- [License](#license)

```
$ composio-agent "What came first, the chicken or the egg?"

  ● Thinking...

  The question of what came first -the chicken or the egg -is one of
  the oldest philosophical puzzles. From a biological standpoint, the egg
  came first. Genetic mutations that led to the first true chicken would
  have occurred in the egg laid by a proto-chicken ancestor.

$ composio-agent --toolkits github "List my open PRs"

  ● Fetching from GitHub...

  You have 3 open pull requests:
  1. feat: add streaming support (#42) -opened 2 days ago
  2. fix: token counting edge case (#38) -opened 5 days ago
  3. docs: update CLI reference (#35) -opened 1 week ago
```

## Key Features

- **Streaming responses** - Real-time token-by-token output via Server-Sent Events
- **Interactive REPL** - Persistent chat sessions with slash commands and color-coded output
- **Composio toolkits** - Connect 250+ external APIs (GitHub, Gmail, Slack, and more) through a single `--toolkits` flag
- **Typed API wrapper** - Minimal, typed interface around OpenAI for programmatic use
- **Token-aware context** - Automatic context window management powered by [tiktoken](https://github.com/openai/tiktoken)
- **Model switching** - Swap between GPT-4o, GPT-4 Turbo, GPT-3.5, and more at runtime via `/model`

## Installation

```bash
# Clone the repository
$ git clone https://github.com/shricodev/agentic-terminal-workbench.git

# Navigate to the directory
$ cd agentic-terminal-workbench

# Install dependencies
$ bun install
```

> **Note:** Requires [Node.js](https://nodejs.org/) v18+ and [Bun](https://bun.sh/).

## Quick Start

Set up your environment variables by copying the example file:

```bash
$ cp .env.example .env
# Then fill in your API keys in .env
```

**Standard chat:**

```bash
$ bun run cli -- "What came first, the chicken or the egg?"
```

**Interactive mode:**

```bash
$ bun run cli
```

**With Composio toolkits:**

```bash
$ bun run cli --toolkits github,gmail "List my unread emails"
```

**Programmatic usage:**

```ts
import { ChatGPTAPI } from "composio-agent";

const api = new ChatGPTAPI({
  apiKey: process.env.OPENAI_API_KEY!,
  model: "gpt-4o",
});

const res = await api.sendMessage("Write a concise summary of Composio.");
console.log(res.text);
```

> **Note:** Streaming is not available when toolkits are enabled due to OpenAI Agents SDK limitations.

## Configuration

| Variable             | Required | Description                            |
| -------------------- | -------- | -------------------------------------- |
| `OPENAI_API_KEY`     | Yes      | Your OpenAI API key                    |
| `COMPOSIO_API_KEY`   | No       | Required when using `--toolkits`       |
| `COMPOSIO_USER_ID`   | No       | Overrides the default Composio user ID |
| `COMPOSIO_CLI_DEBUG` | No       | Set to `1` for verbose lifecycle logs  |

You can also pass `--apiKey` directly to the CLI, or use `--model` to override the model for a session.

## CLI Reference

```
Usage:
  $ bun run cli -- [prompt]

Options:
  -k, --apiKey <key>        OpenAI API key
  -m, --model <model>       Model to use (e.g. gpt-4o)
  -t, --timeout <ms>        Timeout in milliseconds
  -s, --stream              Enable streaming (default: true)
      --toolkits <list>     Comma-separated Composio toolkits to load
```

### Interactive Slash Commands

| Command            | Description                            |
| ------------------ | -------------------------------------- |
| `/help`            | Show available commands                |
| `/model <name>`    | Switch to a different model            |
| `/model list`      | Show the current model                 |
| `/toolkits <list>` | Change active toolkits (Composio mode) |
| `/toolkits list`   | Show active toolkits                   |
| `/clear`           | Clear the screen                       |
| `/quit` or `/exit` | Exit the session                       |

## How Composio Mode Works

When `--toolkits` is provided, the CLI initializes a [Composio](https://composio.dev) session, loads the selected toolkits, and runs an agent through the OpenAI Agents SDK. The agent executes tools internally and returns the final response. This gives the LLM access to real-world APIs -read emails, create GitHub issues, send Slack messages -all from your terminal.

## Project Structure

```
src/
├── cli.ts                  CLI entrypoint with interactive REPL
├── gpt-api.ts              OpenAI chat completion wrapper
├── composio-agent.ts       Composio toolkit integration
├── types.ts                Shared TypeScript interfaces
├── utils.ts                Model validation & token limits
├── index.ts                Public API exports
├── fetch.ts                HTTP fetch helper
├── fetch-sse.ts            Server-Sent Events streaming
└── stream-async-iter.ts    Async iterable stream utilities
```

## Development

```bash
# Watch mode
$ bun run dev

# Production build
$ bun run build

# Generate docs
$ bun run docs

# Run tests (format check)
$ bun run test
```

## Credits

This project is built on top of these excellent open-source projects:

- [OpenAI](https://openai.com/) -LLM provider
- [Composio](https://composio.dev/) -Toolkit integrations for AI agents
- [OpenAI Agents SDK](https://github.com/openai/openai-agents-js) -Agent orchestration
- [tiktoken](https://github.com/openai/tiktoken) -Token counting
- [cac](https://github.com/cacjs/cac) -CLI argument parsing
- [chalk](https://github.com/chalk/chalk) -Terminal styling
- [ora](https://github.com/sindresorhus/ora) -Elegant terminal spinners

## License

[MIT](LICENSE)

---

> GitHub [@shricodev](https://github.com/shricodev)
